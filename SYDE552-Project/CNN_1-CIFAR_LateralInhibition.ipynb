{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"H3WMlQFfDxB2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import models, datasets, transforms\n","from torch.utils.data import DataLoader, Dataset, Subset, random_split\n","from PIL import Image\n","from torchvision.datasets import ImageFolder\n","from tqdm import tqdm\n","import numpy as np\n","from torchvision.models import resnet50\n","from torch.autograd import Variable\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Check if GPU is available and set device accordingly\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"QNCGRHEz4y78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define transformations for training dataset (with data augmentation)\n","transform = transforms.Compose([\n","    #transforms.RandomRotation(15),  # Rotation by Â±15 degrees\n","    #transforms.RandomHorizontalFlip(),  # Horizontal flip\n","    #transforms.RandomVerticalFlip(),  # Uncomment if vertical flip is desired\n","    transforms.ToTensor(),  # Convert images to tensor\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n","])\n","\n","# Load CIFAR-10 dataset\n","trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n","\n","testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wVlnIL9D5xn","executionInfo":{"status":"ok","timestamp":1713239952658,"user_tz":240,"elapsed":2514,"user":{"displayName":"A P","userId":"03103991736051634190"}},"outputId":"18a91653-8a1d-4ac4-dcd0-17b3777100b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["class LateralInhibition(nn.Module):\n","    def __init__(self):\n","        super(LateralInhibition, self).__init__()\n","        # Define the inhibitory kernel\n","        # The kernel has a positive center and negative surround\n","        self.inhibition_kernel = torch.tensor([[-0.2, -0.2, -0.2],\n","                                               [-0.2, 2.0 , -0.2],\n","                                               [-0.2, -0.2, -0.2]], dtype=torch.float32)\n","\n","    def forward(self, x):\n","        # Ensure the kernel is on the same device as the input\n","        kernel = self.inhibition_kernel.to(x.device).view(1, 1, 3, 3)\n","        # Apply the same kernel across all input channels\n","        kernel = kernel.repeat(x.size(1), 1, 1, 1)\n","        # Group the input so that the kernel is applied channel-wise\n","        return F.conv2d(x, kernel, padding=1, groups=x.size(1))"],"metadata":{"id":"G9g8IyDLeh-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNNLateralInhibition(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(CNNLateralInhibition, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=5, stride=1, padding=0)\n","        self.lateral_inhibit1 = LateralInhibition()\n","        self.bn1 = nn.BatchNorm2d(num_features=96)\n","        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=0)\n","        self.bn2 = nn.BatchNorm2d(num_features=256)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(in_features=36864, out_features=num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.lateral_inhibit1(x)\n","        x = F.relu(self.bn1(x))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = self.pool1(x)\n","        x = F.relu(self.conv3(x))\n","        x = F.relu(self.conv4(x))\n","        x = F.relu(self.conv5(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.fc1(x)\n","        return x"],"metadata":{"id":"NEWOcbi6F1FY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","def train(epoch, net, trainloader, optimizer, criterion):\n","    net.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)  # Move data to GPU\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","        # Compute accuracy\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        if i % 2000 == 1999:  # Print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","    # Calculate accuracy after each epoch\n","    accuracy = 100 * correct / total\n","    epoch_list.append(epoch + 1)  # Append epoch number to list\n","    accuracy_list.append(accuracy)  # Append accuracy to list\n","    print('Epoch [%d], Accuracy on training images: %d %%' % (epoch + 1, accuracy))"],"metadata":{"id":"g4fsHd2zFM2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test the model\n","def test(net, testloader):\n","    net.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)  # Move data to GPU\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print('Accuracy on test images: %d %%' % (100 * correct / total))"],"metadata":{"id":"DWOPg_c-4rgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def imshow(img):\n","    img = img.cpu()  # Move img to cpu if it's not already\n","    img = img.numpy()  # Convert from PyTorch tensor to numpy array\n","    img = np.transpose(img, (1, 2, 0))  # Rearrange dimensions to Width x Height x Channels\n","    img = (img - img.min()) / (img.max() - img.min())  # Normalize the image to [0, 1]\n","    plt.imshow(img)\n","    plt.show()\n","\n","# Initialize the lateral inhibition layer\n","lateral_inhibit = LateralInhibition()\n","\n","# Initialize seed to show the same training images\n","torch.manual_seed(0)\n","\n","# Get some random training images\n","dataiter = iter(trainloader)\n","images, _ = next(dataiter)\n","\n","# Apply lateral inhibition\n","processed_images = lateral_inhibit(images)\n","\n","# Show original images\n","print(\"Original Images\")\n","imshow(torchvision.utils.make_grid(images))\n","\n","# Show images after applying lateral inhibition\n","print(\"Images after Lateral Inhibition\")\n","imshow(torchvision.utils.make_grid(processed_images))"],"metadata":{"id":"B5Oe-WRtezwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Iniltialize the model\n","net = CNNLateralInhibition()\n","net.to(device)\n","\n","#Initialize optimizer and Loss function\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"WS_gW6cHESKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lists to store epoch and accuracy values\n","epoch_list = []\n","accuracy_list = []\n","# Train the model\n","for epoch in range(10):  # loop over the dataset multiple times\n","    train(epoch, net, trainloader, optimizer, criterion)\n","\n","# Test the model\n","test(net, testloader)"],"metadata":{"id":"noqs94pLK2nF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713240636085,"user_tz":240,"elapsed":318119,"user":{"displayName":"A P","userId":"03103991736051634190"}},"outputId":"e2323f4f-6ef7-4817-f0e8-25e00ea99bd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1], Accuracy on training images: 48 %\n","Epoch [2], Accuracy on training images: 63 %\n","Epoch [3], Accuracy on training images: 69 %\n","Epoch [4], Accuracy on training images: 73 %\n","Epoch [5], Accuracy on training images: 76 %\n","Epoch [6], Accuracy on training images: 79 %\n","Epoch [7], Accuracy on training images: 81 %\n","Epoch [8], Accuracy on training images: 83 %\n","Epoch [9], Accuracy on training images: 85 %\n","Epoch [10], Accuracy on training images: 87 %\n","Accuracy on test images: 77 %\n"]}]},{"cell_type":"code","source":["# Plot epoch vs accuracy\n","plt.plot(epoch_list, accuracy_list, marker='o')\n","plt.title('Epoch vs Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"zk5IyTM-d1jZ"},"execution_count":null,"outputs":[]}]}